{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f611e410",
   "metadata": {},
   "source": [
    "#### BOT DATA GATE GENERAL INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Gate Developer: Rweyemamu Barongo \n",
    "Email:  ribarongo@bot.go.tz, rbarongo@gmail.com\n",
    "Date:   14 Jan 2025\n",
    "Version: 1.0.1\n",
    "\n",
    "Objectives\n",
    " (1) To ease data collection from internal and external source using one collection point, user-friendly access \n",
    "     and flexibility of data analysis.\n",
    " (2) To provide platform for analysis of voluminous data accross multiple sources and formats \n",
    "     (files, databases, APIs, etc)\n",
    " (3) To provide platform that enables BOT's adoption and execution of advanced data analysis tools using machine learning \n",
    "     and data mining methods to enrich BOT decision insights. \n",
    "\n",
    "Completed modules\n",
    " (1) MSP individual and consolidated reports\n",
    " (2) ITRS reports\n",
    "\n",
    "       \n",
    "To pull individual data reports use the following function \n",
    "   data = read_data(data_group, data_source, data_type, institution_code, start_period, end_period)   \n",
    "   example: data = read_data('MSP','BSIS','01','M100','31-MAY-2024','31-JUL-2024')\n",
    "\n",
    "To pull institution profile use the following function  \n",
    "   data = read_profile('MSP','BSIS','M100')\n",
    "   example:  data = read_profile(data_group, data_source,institution_code)\n",
    "To extract \n",
    "   data frame use data['df']\n",
    "   error use data['error']\n",
    "   information use data['ínfo']\n",
    "To save \n",
    "   example: data['df'].to_csv(\"data.csv\")\n",
    "\n",
    "   \n",
    "Example:\n",
    "Data Groups: MSP, BANK, ...\n",
    "Data Source:      BSIS\n",
    "Data Type or ReportName: \n",
    "   MSP: 01,02,03,04,05,06,07,08,09,10,CONS01..CONS07I..CONS07IV,CONS08..CONS10\n",
    "   ITRS:\n",
    "Institution Code:\n",
    "   MSP: M100\n",
    "Start or end period should be in format 'DD-MON-YYYY' eg '24-DEC-2024'\n",
    "\n",
    "Future extension\n",
    "Add other requested modules and features for users' monitoring of submissions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4533b",
   "metadata": {},
   "source": [
    "#### MSP Data Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64809ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log in to continue.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  RIBARONGO\n",
      "Password:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-08-2025 08:44:56 [INFO] Login successful\n",
      "22-08-2025 08:44:56 [INFO] Connected to data source and executed query.\n",
      "22-08-2025 08:44:56 [INFO] Data successfully retrieved and packed into a DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from utils import read_data, read_profile\n",
    "\n",
    "\n",
    "#DATA\n",
    "#FSP register\n",
    "#res = read_profile('MSP','BSIS','*')\n",
    "#FSP profile\n",
    "res = read_profile('MSP','BSIS','M100')\n",
    "\n",
    "\n",
    "#individual \n",
    "#res = read_data('MSP','BSIS','01','M100','31-MAY-2024','31-JUL-2024')\n",
    "\n",
    "#individual for all institutions\n",
    "#res = read_data('MSP','BSIS','01','*','31-MAY-2024','31-DEC-2024')\n",
    "\n",
    "\n",
    "#consolidated\n",
    "#res = read_data('MSP','BSIS','CONS10','*','30-SEP-2024','30-SEP-2024') # verify cons 8    QBJX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9444c0-1d79-45ab-8f15-3f643dd291d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTITUTIONCODE</th>\n",
       "      <th>REPORTINGDATE</th>\n",
       "      <th>DESCRIPTIONNO</th>\n",
       "      <th>PARTICULARS</th>\n",
       "      <th>AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1. CASH AND CASH EQUIVALENTS (sum a:d)</td>\n",
       "      <td>6.064281e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>(a) Cash in Hand</td>\n",
       "      <td>5.894000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>3</td>\n",
       "      <td>(b) Balances with  Banks and Financial Ins...</td>\n",
       "      <td>1.702805e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>4</td>\n",
       "      <td>(i) Non-Agent Banking  Balances</td>\n",
       "      <td>1.702805e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>5</td>\n",
       "      <td>(ii) Agent-Banking Balances</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>57</td>\n",
       "      <td>(f) General Reserves</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>58</td>\n",
       "      <td>(g) Retained Earnings</td>\n",
       "      <td>2.414339e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>59</td>\n",
       "      <td>(h) Profit/Loss</td>\n",
       "      <td>2.320471e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>60</td>\n",
       "      <td>(i) Other Reserves</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>M100</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>61</td>\n",
       "      <td>16. TOTAL LIABILITIES AND CAPITAL (14+15)</td>\n",
       "      <td>1.052145e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INSTITUTIONCODE REPORTINGDATE  DESCRIPTIONNO  \\\n",
       "0             M100    2024-06-30              1   \n",
       "1             M100    2024-06-30              2   \n",
       "2             M100    2024-06-30              3   \n",
       "3             M100    2024-06-30              4   \n",
       "4             M100    2024-06-30              5   \n",
       "..             ...           ...            ...   \n",
       "56            M100    2024-06-30             57   \n",
       "57            M100    2024-06-30             58   \n",
       "58            M100    2024-06-30             59   \n",
       "59            M100    2024-06-30             60   \n",
       "60            M100    2024-06-30             61   \n",
       "\n",
       "                                          PARTICULARS        AMOUNT  \n",
       "0              1. CASH AND CASH EQUIVALENTS (sum a:d)  6.064281e+06  \n",
       "1                                    (a) Cash in Hand  5.894000e+06  \n",
       "2       (b) Balances with  Banks and Financial Ins...  1.702805e+05  \n",
       "3                     (i) Non-Agent Banking  Balances  1.702805e+05  \n",
       "4                         (ii) Agent-Banking Balances  0.000000e+00  \n",
       "..                                                ...           ...  \n",
       "56                               (f) General Reserves  0.000000e+00  \n",
       "57                              (g) Retained Earnings  2.414339e+07  \n",
       "58                                    (h) Profit/Loss  2.320471e+05  \n",
       "59                                 (i) Other Reserves  0.000000e+00  \n",
       "60          16. TOTAL LIABILITIES AND CAPITAL (14+15)  1.052145e+08  \n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1127c5",
   "metadata": {},
   "source": [
    "#### ITRS Data Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1e5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from utils import read_data, read_profile\n",
    "\n",
    "\n",
    "#DATA\n",
    "#FSP register\n",
    "#res = read_profile('BANK','BSIS','*')\n",
    "#FSP profile\n",
    "#res = read_profile('BANK','BSIS','M100')\n",
    "\n",
    "#exchange rates\n",
    "#res = read_data('ITRS','BSIS','RATES','A129','31-MAY-2024','31-JUL-2024')\n",
    "res = read_data('ITRS','BSIS','URT_RECEIPTS','*','31-AUG-2024','31-AUG-2024')\n",
    "\n",
    "#MONITORING\n",
    "#res = read_data('ITRS','BSIS','MONITORING','A129','30-SEP-2024','30-SEP-2024')  #needs privileges\n",
    "#res = read_data('ITRS','BSIS','OVERALL_ANALYSIS','A129','30-SEP-2024','30-SEP-2024')   #no output\n",
    "#res = read_data('ITRS','BSIS','TRANSFORMATION_ERRORS','*','30-SEP-2024','30-SEP-2024')   \n",
    "\n",
    "#RAW DATA\n",
    "#res = read_data('ITRS','BSIS','URT_PAYMENTS','A129','30-SEP-2024','30-SEP-2024')\n",
    "#res = read_data('ITRS','BSIS','URT_RECEIPTS','A129','30-SEP-2024','30-SEP-2024')\n",
    "#res = read_data('ITRS','BSIS','ZNZ_PAYMENTS','A129','30-SEP-2024','30-SEP-2024')\n",
    "#res = read_data('ITRS','BSIS','ZNZ_RECEIPTS','*','30-SEP-2021','30-SEP-2024')\n",
    "\n",
    "#DATA ANALYSIS\n",
    "#res = read_data('ITRS','BSIS','COUNTRIES_SECTORS_TZS','A129','30-SEP-2024','30-SEP-2024')   \n",
    "#res = read_data('ITRS','BSIS','COUNTRIES_SECTORS_USD','A129','30-SEP-2024','30-SEP-2024')   \n",
    "#res = read_data('ITRS','BSIS','CONSOLIDATED_TZS','A129','30-SEP-2024','30-SEP-2024') \n",
    "#res = read_data('ITRS','BSIS','REGION_SECTOR_TZS','A129','30-SEP-2024','30-SEP-2024') \n",
    "#res = read_data('ITRS','BSIS','REGION_SECTOR_USD','A129','30-SEP-2024','30-SEP-2024')\n",
    "#res = read_data('ITRS','BSIS','URT_PAYMENTS_FINAL','A129','30-SEP-2024','30-SEP-2024') #failed\n",
    "#res = read_data('ITRS','BSIS','URT_RECEIPTS_FINAL','A129','30-SEP-2024','30-SEP-2024')\n",
    "#res = read_data('ITRS','BSIS','ZNZ_PAYMENTS_FINAL','*','30-SEP-2024','30-SEP-2024')\n",
    "#res = read_data('ITRS','BSIS','ZNZ_RECEIPTS_FINAL','*','30-SEP-2024','30-SEP-2024')\n",
    "#QBJX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65d2fae-3a0e-45bf-9d4b-e446e4f5a957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['df']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fbd0a",
   "metadata": {},
   "source": [
    "#### Data Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e12b21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = res['df']\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f33336a",
   "metadata": {},
   "source": [
    "res['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "787b532e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No query found for data type: URT_RECEIPTS.  | Output DataFrame is empty. Check data source or query parameters.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['debug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4769c501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['df'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45905a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=0, step=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4835d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b70338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5c45da",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DESCRIPTIONNO'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mask \u001b[38;5;241m=\u001b[39m ((\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDESCRIPTIONNO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMOUNT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20000000\u001b[39m ))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DESCRIPTIONNO'"
     ]
    }
   ],
   "source": [
    "mask = ((df1['DESCRIPTIONNO']==1) & (df1['AMOUNT'] < 20000000 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a43b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "#res['df'].to_csv(cfg.dataCollectionFolder + \"data.csv\")\n",
    "res['df'].to_csv(\"C:\\\\MSP\\\\dataFiles\\\\data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0331e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05cf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"C:\\\\_rwey\\\\assignments\\\\BSIS and EDI\\\\ITRS\\\\2024\\\\January\\\\\"\n",
    "file = \"A1291078310124.xls\"\n",
    "file_name= data_path + file\n",
    "sheet_name = 'ITRS1_URT_PAYMENTS'\n",
    "columns_to_read = list(range(0, 8))\n",
    "import pandas as pd\n",
    "df  = pd.read_excel(file_name, sheet_name=sheet_name, usecols=columns_to_read, skiprows=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17f7a5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84f88611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchandise Goods</td>\n",
       "      <td>3101000.0</td>\n",
       "      <td>UNITED ARAB EMIRATES</td>\n",
       "      <td>Households</td>\n",
       "      <td>AED</td>\n",
       "      <td>37400.00</td>\n",
       "      <td>NIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Manufacturing services on physical inputs owne...</td>\n",
       "      <td>3201000.0</td>\n",
       "      <td>UNITED ARAB EMIRATES</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>AED</td>\n",
       "      <td>212365.00</td>\n",
       "      <td>NIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Maintenance and repair services n.i.e.</td>\n",
       "      <td>3202000.0</td>\n",
       "      <td>UNITED ARAB EMIRATES</td>\n",
       "      <td>Non - Financial Corporations</td>\n",
       "      <td>AED</td>\n",
       "      <td>50200.00</td>\n",
       "      <td>NIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Passenger transport by sea</td>\n",
       "      <td>3203010.0</td>\n",
       "      <td>UNITED ARAB EMIRATES</td>\n",
       "      <td>Households</td>\n",
       "      <td>AED</td>\n",
       "      <td>90659.25</td>\n",
       "      <td>NIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Freight transport by sea</td>\n",
       "      <td>3203020.0</td>\n",
       "      <td>UNITED ARAB EMIRATES</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>AED</td>\n",
       "      <td>91865.81</td>\n",
       "      <td>NIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a                                                  b          c  \\\n",
       "0  1                                  Merchandise Goods  3101000.0   \n",
       "1  2  Manufacturing services on physical inputs owne...  3201000.0   \n",
       "2  3             Maintenance and repair services n.i.e.  3202000.0   \n",
       "3  4                         Passenger transport by sea  3203010.0   \n",
       "4  5                           Freight transport by sea  3203020.0   \n",
       "\n",
       "                      d                              e    f          g    h  \n",
       "0  UNITED ARAB EMIRATES                     Households  AED   37400.00  NIL  \n",
       "1  UNITED ARAB EMIRATES         Financial Corporations  AED  212365.00  NIL  \n",
       "2  UNITED ARAB EMIRATES  Non - Financial Corporations   AED   50200.00  NIL  \n",
       "3  UNITED ARAB EMIRATES                     Households  AED   90659.25  NIL  \n",
       "4  UNITED ARAB EMIRATES         Financial Corporations  AED   91865.81  NIL  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dc802d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def itrs_bop(reporting_date, user, password, dsn):\n",
    "    \"\"\"\n",
    "    Python function to perform operations similar to the ITRS_BOP PL/SQL procedure.\n",
    "    The results are returned in a Pandas DataFrame instead of being inserted into a temporary table.\n",
    "\n",
    "    :param reporting_date: Date for which the report is generated.\n",
    "    :param user: Database username.\n",
    "    :param password: Database password.\n",
    "    :param dsn: Data Source Name for the Oracle connection.\n",
    "    :return: Pandas DataFrame with processed data.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        oracledb.init_oracle_client()  # Ensure the Oracle client is initialized\n",
    "        conn = oracledb.connect(user=user, password=password, dsn=dsn)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Initialize variables\n",
    "        v_date = reporting_date\n",
    "\n",
    "        # Fetch records from the static table\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT DESCRIPTIONNO, PURPOSE, RECEIPTS_CODE, PAYMENTS_CODE\n",
    "            FROM BSIS_DEV.ITRS_URT_BOP_TEMPLATE\n",
    "            ORDER BY DESCRIPTIONNO ASC\n",
    "        \"\"\")\n",
    "        c_bop_static_table = cursor.fetchall()\n",
    "\n",
    "        # Create an empty DataFrame to store the results\n",
    "        columns = [\n",
    "            \"DESCRIPTIONNO\", \"PURPOSE\", \"RECEIPTS_CODE\", \"PAYMENTS_CODE\",\n",
    "            \"RECEIPTS_AMOUNT\", \"PAYMENTS_AMOUNT\", \"NET_AMOUNT\", \"REG_DATE\"\n",
    "        ]\n",
    "        results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        # Process each record\n",
    "        for record in c_bop_static_table:\n",
    "            description_no, purpose, receipts_code, payments_code = record\n",
    "            v_payments_amount = None\n",
    "            v_receipts_amount = None\n",
    "\n",
    "            # Calculate payments amount\n",
    "            if payments_code is not None:\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT SUM(NVL(AMOUNT_IN_USD_EQV, 0))\n",
    "                    FROM ITRS_URT_PAYMENTS_FINAL\n",
    "                    WHERE REPORTINGDATE = :v_date AND PU_CODE = :payments_code\n",
    "                \"\"\", [v_date, payments_code])\n",
    "                v_payments_amount = cursor.fetchone()[0] or None\n",
    "\n",
    "            # Calculate receipts amount\n",
    "            if receipts_code is not None:\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT SUM(NVL(AMOUNT_IN_USD_EQV, 0))\n",
    "                    FROM ITRS_URT_RECEIPTS_FINAL\n",
    "                    WHERE REPORTINGDATE = :v_date AND PU_CODE = :receipts_code\n",
    "                \"\"\", [v_date, receipts_code])\n",
    "                v_receipts_amount = cursor.fetchone()[0] or None\n",
    "\n",
    "            # Compute net amount\n",
    "            net_amount = (v_receipts_amount or 0) - (v_payments_amount or 0)\n",
    "\n",
    "            # Append the record to the DataFrame\n",
    "            results_df = pd.concat([\n",
    "                results_df,\n",
    "                pd.DataFrame([[\n",
    "                    description_no, purpose, receipts_code, payments_code,\n",
    "                    v_receipts_amount, v_payments_amount, net_amount, v_date\n",
    "                ]], columns=columns)\n",
    "            ], ignore_index=True)\n",
    "\n",
    "        # Perform aggregate operations (example: Goods account)\n",
    "        # Aggregate payments\n",
    "        goods_payments_aggregate = results_df.loc[\n",
    "            results_df[\"PAYMENTS_CODE\"].isin([3101000, 3102000]),\n",
    "            \"PAYMENTS_AMOUNT\"\n",
    "        ].sum()\n",
    "        if goods_payments_aggregate > 0:\n",
    "            results_df.loc[results_df[\"PAYMENTS_CODE\"] == 3100000, \"PAYMENTS_AMOUNT\"] = goods_payments_aggregate\n",
    "\n",
    "        # Aggregate receipts\n",
    "        goods_receipts_aggregate = results_df.loc[\n",
    "            results_df[\"RECEIPTS_CODE\"].isin([2101000, 2102000, 2103000, 2104000]),\n",
    "            \"RECEIPTS_AMOUNT\"\n",
    "        ].sum()\n",
    "        if goods_receipts_aggregate > 0:\n",
    "            results_df.loc[results_df[\"RECEIPTS_CODE\"] == 2100000, \"RECEIPTS_AMOUNT\"] = goods_receipts_aggregate\n",
    "\n",
    "        # Return the DataFrame\n",
    "        return results_df\n",
    "\n",
    "    except oracledb.DatabaseError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "    finally:\n",
    "        # Close connections\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "    # Usage\n",
    "    \n",
    "    df = itrs_bop(reporting_date, user, password, dsn)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "224af4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database error: DPY-2019: python-oracledb thick mode cannot be used because thin mode has already been enabled or a thin mode connection has already been created\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import config as cfg\n",
    "\n",
    "reporting_date = datetime.strptime(\"2024-01-31\", \"%Y-%m-%d\")\n",
    "dsn = cfg.dsn\n",
    "user = cfg.username  # Replace with your username\n",
    "password = cfg.password  # Replace with your password\n",
    "\n",
    "df = itrs_bop(reporting_date, user, password, dsn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ccbf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def itrs_bop(reporting_date, user, password, dsn):\n",
    "    \"\"\"\n",
    "    Main function to perform operations similar to the ITRS_BOP PL/SQL procedure.\n",
    "    Processes service accounts and returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        oracledb.init_oracle_client()  # Ensure Oracle client is initialized\n",
    "        conn = oracledb.connect(user=user, password=password, dsn=dsn)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Fetch static table records\n",
    "        static_table_records = fetch_static_table(cursor)\n",
    "\n",
    "        # Initialize results DataFrame\n",
    "        results_df = initialize_results(static_table_records, reporting_date, cursor)\n",
    "\n",
    "        # Define service accounts\n",
    "        service_accounts = get_service_accounts()\n",
    "\n",
    "        # Apply aggregates for all registered accounts\n",
    "        for account_name, account_details in service_accounts.items():\n",
    "            apply_aggregate(cursor, results_df, account_details, \"PAYMENTS\", reporting_date, user)\n",
    "            apply_aggregate(cursor, results_df, account_details, \"RECEIPTS\", reporting_date, user)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    except oracledb.DatabaseError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "def fetch_static_table(cursor):\n",
    "    \"\"\"Fetches records from the static ITRS_BOP template table.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT DESCRIPTIONNO, PURPOSE, RECEIPTS_CODE, PAYMENTS_CODE\n",
    "        FROM BSIS_DEV.ITRS_URT_BOP_TEMPLATE\n",
    "        ORDER BY DESCRIPTIONNO ASC\n",
    "    \"\"\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "\n",
    "def initialize_results(static_table_records, reporting_date, cursor):\n",
    "    \"\"\"Initializes the results DataFrame.\"\"\"\n",
    "    columns = [\n",
    "        \"DESCRIPTIONNO\", \"PURPOSE\", \"RECEIPTS_CODE\", \"PAYMENTS_CODE\",\n",
    "        \"RECEIPTS_AMOUNT\", \"PAYMENTS_AMOUNT\", \"NET_AMOUNT\", \"REG_DATE\"\n",
    "    ]\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for record in static_table_records:\n",
    "        description_no, purpose, receipts_code, payments_code = record\n",
    "        payments_amount = calculate_amount(cursor, reporting_date, payments_code, \"PAYMENTS\")\n",
    "        receipts_amount = calculate_amount(cursor, reporting_date, receipts_code, \"RECEIPTS\")\n",
    "        net_amount = (receipts_amount or 0) - (payments_amount or 0)\n",
    "\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([[\n",
    "            description_no, purpose, receipts_code, payments_code,\n",
    "            receipts_amount, payments_amount, net_amount, reporting_date\n",
    "        ]], columns=columns)], ignore_index=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def calculate_amount(cursor, reporting_date, code, transaction_type):\n",
    "    \"\"\"Calculates amounts for receipts or payments.\"\"\"\n",
    "    if code is not None:\n",
    "        query = f\"\"\"\n",
    "            SELECT SUM(NVL(AMOUNT_IN_USD_EQV, 0))\n",
    "            FROM ITRS_URT_{transaction_type}_FINAL\n",
    "            WHERE REPORTINGDATE = :reporting_date AND PU_CODE = :code\n",
    "        \"\"\"\n",
    "        cursor.execute(query, [reporting_date, code])\n",
    "        return cursor.fetchone()[0] or None\n",
    "    return None\n",
    "\n",
    "\n",
    "def apply_aggregate(cursor, df, codes, transaction_type, reporting_date, user):\n",
    "    \"\"\"Applies aggregate values for a specific account.\"\"\"\n",
    "    key = f\"{transaction_type.lower()}_codes\"\n",
    "    aggregate_key = f\"aggregate_{transaction_type.lower()}_code\"\n",
    "    selected_codes = codes.get(key, [])\n",
    "    aggregate_code = codes.get(aggregate_key)\n",
    "\n",
    "    if selected_codes and aggregate_code:\n",
    "        total = df.loc[\n",
    "            df[f\"{transaction_type.upper()}_CODE\"].isin(selected_codes),\n",
    "            f\"{transaction_type.upper()}_AMOUNT\"\n",
    "        ].sum()\n",
    "\n",
    "        if total > 0:\n",
    "            df.loc[df[f\"{transaction_type.upper()}_CODE\"] == aggregate_code, f\"{transaction_type.upper()}_AMOUNT\"] = total\n",
    "\n",
    "\n",
    "def register_account(accounts, name, payments_codes, receipts_codes, aggregate_code, aggregate_receipts_code):\n",
    "    \"\"\"Registers a new service account dynamically.\"\"\"\n",
    "    accounts[name] = {\n",
    "        \"payments_codes\": payments_codes,\n",
    "        \"aggregate_code\": aggregate_code,\n",
    "        \"receipts_codes\": receipts_codes,\n",
    "        \"aggregate_receipts_code\": aggregate_receipts_code,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_goods_accounts():\n",
    "    \"\"\"Defines and returns all service accounts.\"\"\"\n",
    "    accounts = {}\n",
    "\n",
    "    # Register existing accounts\n",
    "    register_account(\n",
    "        accounts,\n",
    "        \"Goods Account\",\n",
    "        payments_codes=[3101000, 3102000],\n",
    "        receipts_codes=[2101000, 2102000, 2103000, 2104000],\n",
    "        aggregate_code=3100000,\n",
    "        aggregate_receipts_code=2100000\n",
    "    )\n",
    "\n",
    "    return accounts\n",
    "\n",
    "def get_transport_accounts():\n",
    "    \"\"\"Defines and returns all transport-related service accounts.\"\"\"\n",
    "    accounts = {}\n",
    "\n",
    "    # Sea Transport\n",
    "    register_account(\n",
    "        accounts,\n",
    "        \"Sea Transport\",\n",
    "        payments_codes=[3203010, 3203020, 3203030],\n",
    "        receipts_codes=[2203010, 2203020, 2203030],\n",
    "        aggregate_code=3203001,\n",
    "        aggregate_receipts_code=2203001\n",
    "    )\n",
    "\n",
    "    # Air Transport\n",
    "    register_account(\n",
    "        accounts,\n",
    "        \"Air Transport\",\n",
    "        payments_codes=[3203110, 3203120, 3203130],\n",
    "        receipts_codes=[2203110, 2203120, 2203130],\n",
    "        aggregate_code=3203100,\n",
    "        aggregate_receipts_code=2203100\n",
    "    )\n",
    "\n",
    "    # Rail Transport\n",
    "    register_account(\n",
    "        accounts,\n",
    "        \"Rail Transport\",\n",
    "        payments_codes=[3203210, 3203220, 3203230],\n",
    "        receipts_codes=[2203210, 2203220, 2203230],\n",
    "        aggregate_code=3203200,\n",
    "        aggregate_receipts_code=2203200\n",
    "    )\n",
    "\n",
    "    # Road Transport\n",
    "    register_account(\n",
    "        accounts,\n",
    "        \"Road Transport\",\n",
    "        payments_codes=[3203310, 3203320, 3203330],\n",
    "        receipts_codes=[2203310, 2203320, 2203330],\n",
    "        aggregate_code=3203300,\n",
    "        aggregate_receipts_code=2203300\n",
    "    )\n",
    "\n",
    "    return accounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a8dc58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database error: DPY-2019: python-oracledb thick mode cannot be used because thin mode has already been enabled or a thin mode connection has already been created\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import config as cfg\n",
    "\n",
    "reporting_date = datetime.strptime(\"2024-09-30\", \"%Y-%m-%d\")\n",
    "dsn = cfg.dsn\n",
    "user = cfg.username  # Replace with your username\n",
    "password = cfg.password  # Replace with your password\n",
    "\n",
    "df = itrs_bop(reporting_date, user, password, dsn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "036dcb39-8a5f-4586-864e-4e89ab9aa79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database error: DPY-2019: python-oracledb thick mode cannot be used because thin mode has already been enabled or a thin mode connection has already been created\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = itrs_bop(reporting_date, user, password, dsn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffba3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f94931fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOT reviewed 22 Aug 2025\n",
    "import oracledb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def itrs_bop(reporting_date, user, password, dsn):\n",
    "    \"\"\"\n",
    "    Main function to perform operations similar to the ITRS_BOP PL/SQL procedure.\n",
    "    Processes service accounts and returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        oracledb.init_oracle_client()  # Ensure Oracle client is initialized\n",
    "        conn = oracledb.connect(user=user, password=password, dsn=dsn)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Fetch static table records\n",
    "        static_table_records = fetch_static_table(cursor)\n",
    "\n",
    "        # Initialize results DataFrame\n",
    "        results_df = initialize_results(static_table_records, reporting_date, cursor)\n",
    "\n",
    "        # Define service accounts (load accounts from configuration)\n",
    "        account_groups = load_account_groups()\n",
    "\n",
    "        # Apply aggregates for all registered accounts\n",
    "        for account_group in account_groups:\n",
    "            for account_name, account_details in account_group.items():\n",
    "                apply_aggregate(cursor, results_df, account_details, \"PAYMENTS\", reporting_date, user)\n",
    "                apply_aggregate(cursor, results_df, account_details, \"RECEIPTS\", reporting_date, user)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    except oracledb.DatabaseError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def load_account_groups():\n",
    "    \"\"\"Loads account groups from a predefined structure.\"\"\"\n",
    "    account_groups = []\n",
    "\n",
    "    # Example account groups and their definitions\n",
    "    account_groups.append({\n",
    "        \"Goods Account\": {\n",
    "            \"payments_codes\": [3101000, 3102000],\n",
    "            \"receipts_codes\": [2101000, 2102000, 2103000, 2104000],\n",
    "            \"aggregate_code\": 3100000,\n",
    "            \"aggregate_receipts_code\": 2100000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Sea Transport\": {\n",
    "            \"payments_codes\": [3203010, 3203020, 3203030],\n",
    "            \"receipts_codes\": [2203010, 2203020, 2203030],\n",
    "            \"aggregate_code\": 3203001,\n",
    "            \"aggregate_receipts_code\": 2203001\n",
    "        },\n",
    "        \"Air Transport\": {\n",
    "            \"payments_codes\": [3203110, 3203120, 3203130],\n",
    "            \"receipts_codes\": [2203110, 2203120, 2203130],\n",
    "            \"aggregate_code\": 3203100,\n",
    "            \"aggregate_receipts_code\": 2203100\n",
    "        },\n",
    "        \"Rail Transport\": {\n",
    "            \"payments_codes\": [3203210, 3203220, 3203230],\n",
    "            \"receipts_codes\": [2203210, 2203220, 2203230],\n",
    "            \"aggregate_code\": 3203200,\n",
    "            \"aggregate_receipts_code\": 2203200\n",
    "        },\n",
    "        \"Road Transport\": {\n",
    "            \"payments_codes\": [3203310, 3203320, 3203330],\n",
    "            \"receipts_codes\": [2203310, 2203320, 2203330],\n",
    "            \"aggregate_code\": 3203300,\n",
    "            \"aggregate_receipts_code\": 2203300\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Adding new account groups\n",
    "    account_groups.append({\n",
    "        \"Other Transport\": {\n",
    "            \"payments_codes\": [3203410, 3203420, 3203430, 3203440, 3203450],\n",
    "            \"receipts_codes\": [2203410, 2203420, 2203430, 2203440, 2203450],\n",
    "            \"aggregate_code\": 3203400,\n",
    "            \"aggregate_receipts_code\": 2203400\n",
    "        },\n",
    "        \"Personal Travel\": {\n",
    "            \"payments_codes\": [3204210, 3204220, 3204230],\n",
    "            \"receipts_codes\": [2204210, 2204220, 2204230],\n",
    "            \"aggregate_code\": 3204200,\n",
    "            \"aggregate_receipts_code\": 2204200\n",
    "        },\n",
    "        \"Overall Travel\": {\n",
    "            \"payments_codes\": [3204100, 3204200],\n",
    "            \"receipts_codes\": [2204100, 2204200],\n",
    "            \"aggregate_code\": 3204000,\n",
    "            \"aggregate_receipts_code\": 2204000\n",
    "        },\n",
    "        \"Transport Aggregates\": {\n",
    "            \"payments_codes\": [3203001, 3203100, 3203200, 3203300, 3203400, 3203500],\n",
    "            \"receipts_codes\": [2203001, 2203100, 2203200, 2203300, 2203400, 2203500],\n",
    "            \"aggregate_code\": 3203000,\n",
    "            \"aggregate_receipts_code\": 2203000\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    account_groups.append({\n",
    "        \"Insurance and Pension Services\": {\n",
    "            \"Direct Insurance\": {\n",
    "                \"payments_codes\": [3206110, 3206120],\n",
    "                \"receipts_codes\": [2206110, 2206120],\n",
    "                \"aggregate_code\": 3206100,\n",
    "                \"aggregate_receipts_code\": 2206100\n",
    "            },\n",
    "            \"Reinsurance\": {\n",
    "                \"payments_codes\": [3206210, 3206220],\n",
    "                \"receipts_codes\": [2206210, 2206220],\n",
    "                \"aggregate_code\": 3206200,\n",
    "                \"aggregate_receipts_code\": 2206200\n",
    "            },\n",
    "            \"Pension and Standardised Guarantee Services\": {\n",
    "                \"payments_codes\": [3206410, 3206420],\n",
    "                \"receipts_codes\": [2206410, 2206420],\n",
    "                \"aggregate_code\": 3206400,\n",
    "                \"aggregate_receipts_code\": 2206400\n",
    "            },\n",
    "            \"Overall Insurance and Pension Services\": {\n",
    "                \"payments_codes\": [3206100, 3206200, 3206300, 3206400],\n",
    "                \"receipts_codes\": [2206100, 2206200, 2206300, 2206400],\n",
    "                \"aggregate_code\": 3206000,\n",
    "                \"aggregate_receipts_code\": 2206000\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    account_groups.append({\n",
    "        \"Telecommunications, Computer and Information Services\": {\n",
    "            \"payments_codes\": [3209100, 3209200, 3209300],\n",
    "            \"receipts_codes\": [2209100, 2209200, 2209300],\n",
    "            \"aggregate_code\": 3209000,\n",
    "            \"aggregate_receipts_code\": 2209000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Government Goods and Services n.i.e.\": {\n",
    "            \"payments_codes\": [3212100, 3212200, 3212300],\n",
    "            \"receipts_codes\": [2212100, 2212200, 2212300],\n",
    "            \"aggregate_code\": 3212000,\n",
    "            \"aggregate_receipts_code\": 2212000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Personal, Cultural and Recreational Services\": {\n",
    "            \"payments_codes\": [3211100, 3211200],\n",
    "            \"receipts_codes\": [2211100, 2211200],\n",
    "            \"aggregate_code\": 3211000,\n",
    "            \"aggregate_receipts_code\": 2211000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Other Business Services\": {\n",
    "            \"payments_codes\": [3210100, 3210200, 3210300],\n",
    "            \"receipts_codes\": [2210100, 2210200, 2210300],\n",
    "            \"aggregate_code\": 3210000,\n",
    "            \"aggregate_receipts_code\": 2210000\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    account_groups.append({\n",
    "        \"Overall Services\": {\n",
    "            \"payments_codes\": [3201000, 3202000, 3203000, 3204000, 3205000, 3206000, 3207000, 3208000, 3209000, 3210000, 3211000, 3212000],\n",
    "            \"receipts_codes\": [2201000, 2202000, 2203000, 2204000, 2205000, 2206000, 2207000, 2208000, 2209000, 2210000, 2211000, 2212000],\n",
    "            \"aggregate_code\": 3200000,\n",
    "            \"aggregate_receipts_code\": 2200000\n",
    "         }\n",
    "    })\n",
    "\n",
    "    # Primary Income Account Group (2301000 and 3301000)\n",
    "    account_groups.append({\n",
    "        \"Primary Income\": {\n",
    "            \"payments_codes\": [3301100],\n",
    "            \"receipts_codes\": [2301100],\n",
    "            \"aggregate_code\": 3301000,\n",
    "            \"aggregate_receipts_code\": 2301000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Salaries and Wages Account Group (2301100 and 3301100)\n",
    "    account_groups.append({\n",
    "        \"Salaries and Wages\": {\n",
    "            \"payments_codes\": [3302111],\n",
    "            \"receipts_codes\": [2302111],\n",
    "            \"aggregate_code\": 3302100,\n",
    "            \"aggregate_receipts_code\": 2302100\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Portfolio Investment Account Group (2302200 and 3302200)\n",
    "    account_groups.append({\n",
    "        \"Portfolio Investment\": {\n",
    "            \"payments_codes\": [3302210, 3302211, 3302220, 3302221, 3302230],\n",
    "            \"receipts_codes\": [2302210, 2302211, 2302220, 2302221, 2302230],\n",
    "            \"aggregate_code\": 3302200,\n",
    "            \"aggregate_receipts_code\": 2302200\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Other Investment Account Group (2302300 and 3302300)\n",
    "    account_groups.append({\n",
    "        \"Other Investment\": {\n",
    "            \"payments_codes\": [3302310, 3302320, 3302321, 3302330],\n",
    "            \"receipts_codes\": [2302310, 2302320, 2302321, 2302330],\n",
    "            \"aggregate_code\": 3302300,\n",
    "            \"aggregate_receipts_code\": 2302300\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Compensation of Employees Account Group (2301000 and 3301000)\n",
    "    account_groups.append({\n",
    "        \"Compensation of Employees\": {\n",
    "            \"payments_codes\": [3302100, 3302200, 3302300],\n",
    "            \"receipts_codes\": [2302100, 2302200, 2302300],\n",
    "            \"aggregate_code\": 3302000,\n",
    "            \"aggregate_receipts_code\": 2302000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Reserve Assets Account Group (2303000)\n",
    "    account_groups.append({\n",
    "        \"Reserve Assets\": {\n",
    "            \"payments_codes\": [],\n",
    "            \"receipts_codes\": [2303100, 2303200],\n",
    "            \"aggregate_code\": 2303000,\n",
    "            \"aggregate_receipts_code\": 2303000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Other Primary Income Account Group (2304000 and 3303000)\n",
    "    account_groups.append({\n",
    "        \"Other Primary Income\": {\n",
    "            \"payments_codes\": [3303100, 3303200],\n",
    "            \"receipts_codes\": [2304100, 2304200],\n",
    "            \"aggregate_code\": 3303000,\n",
    "            \"aggregate_receipts_code\": 2304000\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Other Primary Income Account Group (2304000 and 3303000)\n",
    "    account_groups.append({\n",
    "        \"Other Primary Income\": {\n",
    "            \"payments_codes\": [3303100, 3303200],\n",
    "            \"receipts_codes\": [2304100, 2304200],\n",
    "            \"aggregate_code\": 3303000,\n",
    "            \"aggregate_receipts_code\": 2304000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Primary Income Account Group (2305000 and 3304000)\n",
    "    account_groups.append({\n",
    "        \"Primary Income\": {\n",
    "            \"payments_codes\": [3304100, 3304200],\n",
    "            \"receipts_codes\": [2305100, 2305200],\n",
    "            \"aggregate_code\": 3304000,\n",
    "            \"aggregate_receipts_code\": 2305000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Secondary Income Account Group (2306000 and 3305000)\n",
    "    account_groups.append({\n",
    "        \"Secondary Income\": {\n",
    "            \"payments_codes\": [3305100, 3305200],\n",
    "            \"receipts_codes\": [2306100, 2306200],\n",
    "            \"aggregate_code\": 3305000,\n",
    "            \"aggregate_receipts_code\": 2306000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Tertiary Income Account Group (2307000 and 3306000)\n",
    "    account_groups.append({\n",
    "        \"Tertiary Income\": {\n",
    "            \"payments_codes\": [3306100, 3306200],\n",
    "            \"receipts_codes\": [2307100, 2307200],\n",
    "            \"aggregate_code\": 3306000,\n",
    "            \"aggregate_receipts_code\": 2307000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Quaternary Income Account Group (2308000 and 3307000)\n",
    "    account_groups.append({\n",
    "        \"Quaternary Income\": {\n",
    "            \"payments_codes\": [3307100, 3307200],\n",
    "            \"receipts_codes\": [2308100, 2308200],\n",
    "            \"aggregate_code\": 3307000,\n",
    "            \"aggregate_receipts_code\": 2308000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Other Expenses Account Group (2309000 and 3308000)\n",
    "    account_groups.append({\n",
    "        \"Other Expenses\": {\n",
    "            \"payments_codes\": [3308100, 3308200],\n",
    "            \"receipts_codes\": [2309100, 2309200],\n",
    "            \"aggregate_code\": 3308000,\n",
    "            \"aggregate_receipts_code\": 2309000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Primary Expenses Account Group (2310000 and 3309000)\n",
    "    account_groups.append({\n",
    "        \"Primary Expenses\": {\n",
    "            \"payments_codes\": [3309100, 3309200],\n",
    "            \"receipts_codes\": [2310100, 2310200],\n",
    "            \"aggregate_code\": 3309000,\n",
    "            \"aggregate_receipts_code\": 2310000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Secondary Expenses Account Group (2311000 and 3310000)\n",
    "    account_groups.append({\n",
    "        \"Secondary Expenses\": {\n",
    "            \"payments_codes\": [3310100, 3310200],\n",
    "            \"receipts_codes\": [2311100, 2311200],\n",
    "            \"aggregate_code\": 3310000,\n",
    "            \"aggregate_receipts_code\": 2311000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Tertiary Expenses Account Group (2312000 and 3311000)\n",
    "    account_groups.append({\n",
    "        \"Tertiary Expenses\": {\n",
    "            \"payments_codes\": [3311100, 3311200],\n",
    "            \"receipts_codes\": [2312100, 2312200],\n",
    "            \"aggregate_code\": 3311000,\n",
    "            \"aggregate_receipts_code\": 2312000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Quaternary Expenses Account Group (2313000 and 3312000)\n",
    "    account_groups.append({\n",
    "        \"Quaternary Expenses\": {\n",
    "            \"payments_codes\": [3312100, 3312200],\n",
    "            \"receipts_codes\": [2313100, 2313200],\n",
    "            \"aggregate_code\": 3312000,\n",
    "            \"aggregate_receipts_code\": 2313000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Direct investment in Tanzania\": {\n",
    "            \"payments_codes\": [3601210, 3601220, 3601230],\n",
    "            \"receipts_codes\": [2601210, 2601220, 2601230],\n",
    "            \"aggregate_code\": 3601200,\n",
    "            \"aggregate_receipts_code\": 2601200\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Direct Investment\": {\n",
    "            \"payments_codes\": [3601100, 3601200],\n",
    "            \"receipts_codes\": [2601100, 2601200],\n",
    "            \"aggregate_code\": 3601000,\n",
    "            \"aggregate_receipts_code\": 2601000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Assets\": {\n",
    "            \"payments_codes\": [3602110, 3602120],\n",
    "            \"receipts_codes\": [2602110, 2602120],\n",
    "            \"aggregate_code\": 3602100,\n",
    "            \"aggregate_receipts_code\": 2602100\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Liabilities\": {\n",
    "            \"payments_codes\": [3602210, 3602220],\n",
    "            \"receipts_codes\": [2602210, 2602220],\n",
    "            \"aggregate_code\": 3602200,\n",
    "            \"aggregate_receipts_code\": 2602200\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Portfolio Investment\": {\n",
    "            \"payments_codes\": [3601100, 3601200],\n",
    "            \"receipts_codes\": [2601100, 2601200],\n",
    "            \"aggregate_code\": 3602000,\n",
    "            \"aggregate_receipts_code\": 2602000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Assets\": {\n",
    "            \"payments_codes\": [3603110, 3603120, 3603130, 3603140],\n",
    "            \"receipts_codes\": [2603110, 2603120, 2603130, 2603140],\n",
    "            \"aggregate_code\": 3603100,\n",
    "            \"aggregate_receipts_code\": 2603100\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Liabilities\": {\n",
    "            \"payments_codes\": [3603210, 3603220, 3603230, 3603240],\n",
    "            \"receipts_codes\": [2603210, 2603220, 2603230, 2603240],\n",
    "            \"aggregate_code\": 3603200,\n",
    "            \"aggregate_receipts_code\": 2603200\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Other Investment\": {\n",
    "            \"payments_codes\": [3603100, 3603200],\n",
    "            \"receipts_codes\": [2603100, 2603200],\n",
    "            \"aggregate_code\": 3603000,\n",
    "            \"aggregate_receipts_code\": 2603000\n",
    "        }\n",
    "    })\n",
    "\n",
    "    account_groups.append({\n",
    "        \"Financial Account\": {\n",
    "            \"payments_codes\": [3601000, 3602000, 3603000],\n",
    "            \"receipts_codes\": [2601000, 2602000, 2603000],\n",
    "            \"aggregate_code\": 3600000,\n",
    "            \"aggregate_receipts_code\": 2600000\n",
    "        }\n",
    "    })\n",
    "\n",
    "\n",
    "    # You can load more account groups here by appending dictionaries for each group\n",
    "\n",
    "    return account_groups\n",
    "\n",
    "def fetch_static_table(cursor):\n",
    "    \"\"\"Fetches records from the static ITRS_BOP template table.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT DESCRIPTIONNO, PURPOSE, RECEIPTS_CODE, PAYMENTS_CODE\n",
    "        FROM BSIS_DEV.ITRS_URT_BOP_TEMPLATE\n",
    "        ORDER BY DESCRIPTIONNO ASC\n",
    "    \"\"\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def initialize_results(static_table_records, reporting_date, cursor):\n",
    "    \"\"\"Initializes the results DataFrame.\"\"\"\n",
    "    columns = [\n",
    "        \"DESCRIPTIONNO\", \"PURPOSE\", \"RECEIPTS_CODE\", \"PAYMENTS_CODE\",\n",
    "        \"RECEIPTS_AMOUNT\", \"PAYMENTS_AMOUNT\", \"NET_AMOUNT\", \"REG_DATE\"\n",
    "    ]\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for record in static_table_records:\n",
    "        description_no, purpose, receipts_code, payments_code = record\n",
    "        payments_amount = calculate_amount(cursor, reporting_date, payments_code, \"PAYMENTS\")\n",
    "        receipts_amount = calculate_amount(cursor, reporting_date, receipts_code, \"RECEIPTS\")\n",
    "        net_amount = (receipts_amount or 0) - (payments_amount or 0)\n",
    "\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([[ \n",
    "            description_no, purpose, receipts_code, payments_code,\n",
    "            receipts_amount, payments_amount, net_amount, reporting_date\n",
    "        ]], columns=columns)], ignore_index=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def calculate_amount(cursor, reporting_date, code, transaction_type):\n",
    "    \"\"\"Calculates amounts for receipts or payments.\"\"\"\n",
    "    if code is not None:\n",
    "        query = f\"\"\"\n",
    "            SELECT SUM(NVL(AMOUNT_IN_USD_EQV, 0))\n",
    "            FROM ITRS_URT_{transaction_type}_FINAL\n",
    "            WHERE REPORTINGDATE = :reporting_date AND PU_CODE = :code\n",
    "        \"\"\"\n",
    "        cursor.execute(query, [reporting_date, code])\n",
    "        return cursor.fetchone()[0] or None\n",
    "    return None\n",
    "\n",
    "def apply_aggregate(cursor, df, codes, transaction_type, reporting_date, user):\n",
    "    \"\"\"Applies aggregate values for a specific account.\"\"\"\n",
    "    key = f\"{transaction_type.lower()}_codes\"\n",
    "    aggregate_key = f\"aggregate_{transaction_type.lower()}_code\"\n",
    "    selected_codes = codes.get(key, [])\n",
    "    aggregate_code = codes.get(aggregate_key)\n",
    "\n",
    "    if selected_codes and aggregate_code:\n",
    "        total = df.loc[\n",
    "            df[f\"{transaction_type.upper()}_CODE\"].isin(selected_codes),\n",
    "            f\"{transaction_type.upper()}_AMOUNT\"\n",
    "        ].sum()\n",
    "\n",
    "        if total > 0:\n",
    "            df.loc[df[f\"{transaction_type.upper()}_CODE\"] == aggregate_code, f\"{transaction_type.upper()}_AMOUNT\"] = total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f540a-2ba0-490b-96ee-efba5efd6886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c87869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(self, username: str, new_password: str) -> None:\n",
    "    \"\"\"\n",
    "        Send the new password to the user's email.\n",
    "        :param username: The username whose password was reset.\n",
    "        :param new_password: The new password to send.\n",
    "        \"\"\"\n",
    "    email = f\"{username}@bot.go.tz\"\n",
    "    subject = \"Password Reset Notification\"\n",
    "    body = (\n",
    "        f\"Dear {username},\\n\\n\"\n",
    "        f\"Your password has been successfully reset.\\n\\n\"\n",
    "        f\"New Password: {new_password}\\n\\n\"\n",
    "        f\"Please change your password immediately after logging in.\\n\\n\"\n",
    "        f\"Best regards,\\n\"\n",
    "        f\"Bank of Tanzania Support Team\"\n",
    "    )\n",
    "\n",
    "    # Prepare the email payload\n",
    "    email_payload = {\n",
    "        \"to\": email,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"msaada_username\": \"ribarongo2\",\n",
    "        \"msaada_password\": \"ccc\",\n",
    "        \"url\": \"https://owa.bot.go.tz/owa\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Simulate email sending using the specified URL\n",
    "        response = requests.post(\n",
    "            url=\"https://owa.bot.go.tz/owa/send-email\",  # Adjust endpoint as needed\n",
    "            json=email_payload\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Email sent successfully to {email}.\")\n",
    "        else:\n",
    "            print(f\"Failed to send email to {email}. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while sending the email: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd34966",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'send_email' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43msend_email\u001b[49m(username\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRIBARONGO\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mribarongo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'send_email' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "test = send_email(username=\"RIBARONGO\", new_password=\"ribarongo\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acce11",
   "metadata": {},
   "source": [
    "#### ITRS Records Reconciliation in Raw Files, Raw EDI, Raw BSIS, and BSIS after Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3899cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Define the date conversion function\n",
    "def convert_to_formatted_date(filename):\n",
    "    date_string = filename[8:14]\n",
    "    try:\n",
    "        # Convert the date string to a datetime object\n",
    "        #eporting_date = datetime.strptime(date_string, '%d%m%y')\n",
    "        # Format the datetime object as \"31-Jan-24\"\n",
    "        #return reporting_date.strftime('%d-%b-%y')\n",
    "        \n",
    "        # Convert the date string to a datetime object\n",
    "        reporting_date = datetime.strptime(date_string, '%d%m%y')\n",
    "        # Format the datetime object as \"YYYY-MM-DD\"\n",
    "        return reporting_date.strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        # Return None or handle invalid dates\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6eb885c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SNO             PURPOSE       CODE       COUNTRY                  SECTOR  \\\n",
      "0    1           Re-Export  2103000.0  SOUTH AFRICA  Financial Corporations   \n",
      "1    2  Merchandise Goods   2101000.0         CHINA              Households   \n",
      "\n",
      "  CURRENCY    AMOUNT DESCRIPTION REPORTINGDATE INSTITUTIONCODE  \n",
      "0      AED     32.00         NIL    2024-01-31            A129  \n",
      "1      CNY  28396.48         NIL    2024-01-31            A129  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\255759804774\\AppData\\Local\\Temp\\ipykernel_46808\\1697658187.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['REPORTINGDATE'] = convert_to_formatted_date(file)\n",
      "C:\\Users\\255759804774\\AppData\\Local\\Temp\\ipykernel_46808\\1697658187.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['INSTITUTIONCODE'] = file[:4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11632"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=\"C:\\\\_rwey\\\\assignments\\\\BSIS and EDI\\\\ITRS\\\\2024\\\\January\\\\\"\n",
    "file = \"A1291078310124.xls\"\n",
    "\n",
    "# Define the column names\n",
    "columns = ['SNO', 'PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "\n",
    "# Read the Excel file starting from row 8 and apply column names\n",
    "data = pd.read_excel(\n",
    "    path + file,\n",
    "    sheet_name='ITRS2_URT_RECEIPTS',  # Specify the sheet name\n",
    "    usecols=\"A:H\",       # Select columns A to H\n",
    "    skiprows=7,          # Skip the first 7 rows\n",
    "    names=columns        # Apply defined column names\n",
    ")\n",
    "\n",
    "# Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\n",
    "filtered_data = data.dropna(subset=['PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "#filtered_data['REPORTINGDATE'] = filtered_data['file'].apply(convert_to_formatted_date)\n",
    "\n",
    "#filtered_data['INSTITUTIONCODE'] = filtered_data['file'].apply(lambda x: x[:4])\n",
    "filtered_data['REPORTINGDATE'] = convert_to_formatted_date(file)\n",
    "filtered_data['INSTITUTIONCODE'] = file[:4]\n",
    "\n",
    "\n",
    "# Display the filtered data\n",
    "print(filtered_data.head(2))\n",
    "\n",
    "filtered_data.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9140323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNO</th>\n",
       "      <th>PURPOSE</th>\n",
       "      <th>CODE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>CURRENCY</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>REPORTINGDATE</th>\n",
       "      <th>INSTITUTIONCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Re-Export</td>\n",
       "      <td>2103000.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>AED</td>\n",
       "      <td>32.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Merchandise Goods</td>\n",
       "      <td>2101000.0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>Households</td>\n",
       "      <td>CNY</td>\n",
       "      <td>28396.48</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Merchanting</td>\n",
       "      <td>2104000.0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>Households</td>\n",
       "      <td>CNY</td>\n",
       "      <td>67683.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturing services on physical inputs owne...</td>\n",
       "      <td>2201000.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>10841.12</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Maintenance and repair services n.i.e.</td>\n",
       "      <td>2202000.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>875.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Passenger transport by air</td>\n",
       "      <td>2203110.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>3570.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Freight transport by air</td>\n",
       "      <td>2203120.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>2050.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Other air</td>\n",
       "      <td>2203130.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>NPISHs (NGOs)</td>\n",
       "      <td>DKK</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Freight transport by sea</td>\n",
       "      <td>2203020.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Other sea</td>\n",
       "      <td>2203030.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>1100.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Postal and courier services</td>\n",
       "      <td>2203500.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>1775.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>2204100.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>21775.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Health-related expenditure</td>\n",
       "      <td>2204210.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>52400.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Education-related expenditure</td>\n",
       "      <td>2204220.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>199975.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Other personal travel (Tourism-related services)</td>\n",
       "      <td>2204230.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Households</td>\n",
       "      <td>DKK</td>\n",
       "      <td>2975.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Construction</td>\n",
       "      <td>2205000.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>16475.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Direct insurance</td>\n",
       "      <td>2206100.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>200.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Premium Received</td>\n",
       "      <td>2206110.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>15975.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Claims received</td>\n",
       "      <td>2206120.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Non - Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>2352.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Reinsurance</td>\n",
       "      <td>2206200.0</td>\n",
       "      <td>DENMARK</td>\n",
       "      <td>Financial Corporations</td>\n",
       "      <td>DKK</td>\n",
       "      <td>4002.00</td>\n",
       "      <td>NIL</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SNO                                            PURPOSE       CODE  \\\n",
       "0     1                                          Re-Export  2103000.0   \n",
       "1     2                                 Merchandise Goods   2101000.0   \n",
       "2     3                                        Merchanting  2104000.0   \n",
       "3     4  Manufacturing services on physical inputs owne...  2201000.0   \n",
       "4     5             Maintenance and repair services n.i.e.  2202000.0   \n",
       "5     6                         Passenger transport by air  2203110.0   \n",
       "6     7                           Freight transport by air  2203120.0   \n",
       "7     8                                          Other air  2203130.0   \n",
       "8     9                           Freight transport by sea  2203020.0   \n",
       "9    10                                         Other sea   2203030.0   \n",
       "10   11                        Postal and courier services  2203500.0   \n",
       "11   12                                    Business travel  2204100.0   \n",
       "12   13                         Health-related expenditure  2204210.0   \n",
       "13   14                      Education-related expenditure  2204220.0   \n",
       "14   15   Other personal travel (Tourism-related services)  2204230.0   \n",
       "15   16                                       Construction  2205000.0   \n",
       "16   17                                   Direct insurance  2206100.0   \n",
       "17   18                                   Premium Received  2206110.0   \n",
       "18   19                                    Claims received  2206120.0   \n",
       "19   20                                        Reinsurance  2206200.0   \n",
       "\n",
       "         COUNTRY                         SECTOR CURRENCY     AMOUNT  \\\n",
       "0   SOUTH AFRICA         Financial Corporations      AED      32.00   \n",
       "1          CHINA                     Households      CNY   28396.48   \n",
       "2          CHINA                     Households      CNY   67683.00   \n",
       "3        DENMARK         Financial Corporations      DKK   10841.12   \n",
       "4        DENMARK                     Households      DKK     875.00   \n",
       "5        DENMARK                     Households      DKK    3570.00   \n",
       "6        DENMARK                     Households      DKK    2050.00   \n",
       "7        DENMARK                  NPISHs (NGOs)      DKK    1600.00   \n",
       "8        DENMARK         Financial Corporations      DKK    4000.00   \n",
       "9        DENMARK                     Households      DKK    1100.00   \n",
       "10       DENMARK                     Households      DKK    1775.00   \n",
       "11       DENMARK                     Households      DKK   21775.00   \n",
       "12       DENMARK                     Households      DKK   52400.00   \n",
       "13       DENMARK                     Households      DKK  199975.00   \n",
       "14       DENMARK                     Households      DKK    2975.00   \n",
       "15       DENMARK         Financial Corporations      DKK   16475.00   \n",
       "16       DENMARK         Financial Corporations      DKK     200.00   \n",
       "17       DENMARK         Financial Corporations      DKK   15975.00   \n",
       "18       DENMARK  Non - Financial Corporations       DKK    2352.00   \n",
       "19       DENMARK         Financial Corporations      DKK    4002.00   \n",
       "\n",
       "   DESCRIPTION REPORTINGDATE INSTITUTIONCODE  \n",
       "0          NIL    2024-01-31            A129  \n",
       "1          NIL    2024-01-31            A129  \n",
       "2          NIL    2024-01-31            A129  \n",
       "3          NIL    2024-01-31            A129  \n",
       "4          NIL    2024-01-31            A129  \n",
       "5          NIL    2024-01-31            A129  \n",
       "6          NIL    2024-01-31            A129  \n",
       "7          NIL    2024-01-31            A129  \n",
       "8          NIL    2024-01-31            A129  \n",
       "9          NIL    2024-01-31            A129  \n",
       "10         NIL    2024-01-31            A129  \n",
       "11         NIL    2024-01-31            A129  \n",
       "12         NIL    2024-01-31            A129  \n",
       "13         NIL    2024-01-31            A129  \n",
       "14         NIL    2024-01-31            A129  \n",
       "15         NIL    2024-01-31            A129  \n",
       "16         NIL    2024-01-31            A129  \n",
       "17         NIL    2024-01-31            A129  \n",
       "18         NIL    2024-01-31            A129  \n",
       "19         NIL    2024-01-31            A129  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "107c65f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'310124'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[8:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54aca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bacb5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Month            Filename  FILES_RECEIPTS INSTITUTIONCODE REPORTINGDATE\n",
      "0    April  A1241078300424.xls             235            A124    2024-04-30\n",
      "1    April  A1251078300424.xls             402            A125    2024-04-30\n",
      "2    April  A1281078300424.xls             291            A128    2024-04-30\n",
      "3    April  A1291078300424.xls            9746            A129    2024-04-30\n",
      "4    April  A1341078300424.xls             100            A134    2024-04-30\n",
      "..     ...                 ...             ...             ...           ...\n",
      "188    May  A1831078310524.xls              98            A183    2024-05-31\n",
      "189    May  A1841078310524.xls            1892            A184    2024-05-31\n",
      "190    May  A1891078310524.xls               1            A189    2024-05-31\n",
      "191    May  A1961078310524.xls              14            A196    2024-05-31\n",
      "192    May  A1991078310524.xls             120            A199    2024-05-31\n",
      "\n",
      "[193 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the root path where the monthly folders are located\n",
    "root_path = r\"C:\\\\_rwey\\\\assignments\\\\BSIS and EDI\\\\ITRS\\\\2024\\\\\"\n",
    "\n",
    "# Define the column names\n",
    "columns = ['SNO', 'PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "\n",
    "# Create a list to hold the output data\n",
    "output_summary = []\n",
    "\n",
    "# Iterate through all month folders in the root path\n",
    "for month_folder in os.listdir(root_path):\n",
    "    month_path = os.path.join(root_path, month_folder)\n",
    "\n",
    "    # Check if the current path is a directory (month folder)\n",
    "    if os.path.isdir(month_path):\n",
    "        # Iterate through all files in the month folder\n",
    "        for file in os.listdir(month_path):\n",
    "            file_path = os.path.join(month_path, file)\n",
    "\n",
    "            # Check if the file is an Excel file\n",
    "            if file.endswith(\".xls\") or file.endswith(\".xlsx\"):\n",
    "                try:\n",
    "                    # Read the Excel file\n",
    "                    data = pd.read_excel(\n",
    "                        file_path,\n",
    "                        sheet_name='ITRS2_URT_RECEIPTS',  # Specify the sheet name\n",
    "                        usecols=\"A:H\",                   # Select columns A to H\n",
    "                        skiprows=7,                      # Skip the first 7 rows\n",
    "                        names=columns                    # Apply defined column names\n",
    "                    )\n",
    "\n",
    "                    # Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\n",
    "                    filtered_data = data.dropna(subset=['PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "                    # Append the summary details to the output list\n",
    "                    output_summary.append({\n",
    "                        \"Month\": month_folder,\n",
    "                        \"Filename\": file,\n",
    "                        \"FILES_RECEIPTS\": filtered_data.shape[0],\n",
    "                        \"INSTITUTIONCODE\": file[:4],\n",
    "                        \"REPORTINGDATE\" : convert_to_formatted_date(file)\n",
    "                        \n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    # Append an error message for files that could not be processed\n",
    "                    output_summary.append({\n",
    "                        \"Month\": month_folder,\n",
    "                        \"Filename\": file,\n",
    "                        \"Records\": f\"Error: {str(e)}\"\n",
    "                    })\n",
    "\n",
    "# Convert the summary list to a DataFrame for tabular display\n",
    "summary_df = pd.DataFrame(output_summary)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n",
    "\n",
    "# Optionally, save the summary to a CSV file\n",
    "summary_df.to_csv(r\"C:\\\\_rwey\\\\assignments\\\\BSIS and EDI\\\\ITRS\\\\2024\\\\summary_output.csv\", index=False)\n",
    "\n",
    "#summary_df['INSTITUTIONCODE'] = summary_df['INSTITUTIONCODE'].apply(x:x[:])\n",
    "\n",
    "\n",
    "#summary_df['FormattedReportingDate'] = summary_df['Filename'].apply(convert_to_formatted_date)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cd2b0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;66;03m# Read the Excel file\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mITRS2_URT_RECEIPTS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the sheet name\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA:H\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# Select columns A to H\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Skip the first 7 rows\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Apply defined column names\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;66;03m# Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\u001b[39;00m\n\u001b[0;32m     32\u001b[0m         filtered_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPURPOSE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCODE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOUNTRY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSECTOR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCURRENCY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAMOUNT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#alternative: read files from one path for all data\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the path where all files are located\n",
    "data_path = r\"C:\\edi_data\"\n",
    "\n",
    "# Define the column names\n",
    "columns = ['SNO', 'PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "\n",
    "# Create a list to hold the output data\n",
    "output_summary = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file in os.listdir(data_path):\n",
    "    file_path = os.path.join(data_path, file)\n",
    "\n",
    "    # Check if the file is an Excel file\n",
    "    if file.endswith(\".xls\") or file.endswith(\".xlsx\"):\n",
    "        try:\n",
    "            # Read the Excel file\n",
    "            data = pd.read_excel(\n",
    "                file_path,\n",
    "                sheet_name='ITRS2_URT_RECEIPTS',  # Specify the sheet name\n",
    "                usecols=\"A:H\",                   # Select columns A to H\n",
    "                skiprows=7,                      # Skip the first 7 rows\n",
    "                names=columns                    # Apply defined column names\n",
    "            )\n",
    "\n",
    "            # Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\n",
    "            filtered_data = data.dropna(subset=['PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "            # Append the summary details to the output list\n",
    "            output_summary.append({\n",
    "                \"Filename\": file,\n",
    "                \"FILES_RECEIPTS\": filtered_data.shape[0],\n",
    "                \"INSTITUTIONCODE\": file[:4],\n",
    "                \"REPORTINGDATE\": datetime.strptime(file[8:14], '%d%m%y').strftime('%Y-%m-%d')  # Convert to \"YYYY-MM-DD\" format\n",
    "            })\n",
    "        except Exception as e:\n",
    "            # Append an error message for files that could not be processed\n",
    "            output_summary.append({\n",
    "                \"Filename\": file,\n",
    "                \"FILES_RECEIPTS\": f\"Error: {str(e)}\",\n",
    "                \"INSTITUTIONCODE\": None,\n",
    "                \"REPORTINGDATE\": None\n",
    "            })\n",
    "\n",
    "# Convert the summary list to a DataFrame for tabular display\n",
    "summary_df = pd.DataFrame(output_summary)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n",
    "\n",
    "# Optionally, save the summary to a CSV file\n",
    "summary_df.to_csv(r\"C:\\edi_data\\summary_receipts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f24dcb",
   "metadata": {},
   "source": [
    "#### Reexecute with cuncurrent tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c4c276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Filename                                     FILES_RECEIPTS  \\\n",
      "0      A1241078280221.xls                                                222   \n",
      "1      A1241078280222.xls                                                241   \n",
      "2      A1241078280223.xls                                                244   \n",
      "3      A1241078290220.xls  Error: Number of passed names did not match nu...   \n",
      "4      A1241078290224.xls                                                258   \n",
      "...                   ...                                                ...   \n",
      "1701  PA1291078310722.xls                Error: unconverted data remains: 72   \n",
      "1702  PA1581078300620.xls                Error: unconverted data remains: 62   \n",
      "1703  PA1601078310523.xls                Error: unconverted data remains: 52   \n",
      "1704  PA1631078310324.xls                Error: unconverted data remains: 32   \n",
      "1705  PA1971078310321.xls                Error: unconverted data remains: 32   \n",
      "\n",
      "     INSTITUTIONCODE REPORTINGDATE  \n",
      "0               A124    2021-02-28  \n",
      "1               A124    2022-02-28  \n",
      "2               A124    2023-02-28  \n",
      "3               None          None  \n",
      "4               A124    2024-02-29  \n",
      "...              ...           ...  \n",
      "1701            None          None  \n",
      "1702            None          None  \n",
      "1703            None          None  \n",
      "1704            None          None  \n",
      "1705            None          None  \n",
      "\n",
      "[1706 rows x 4 columns]\n",
      "Summary saved to C:\\edi_data\\summary_receipts2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "\n",
    "# Configure logging for error tracking\n",
    "logging.basicConfig(\n",
    "    filename=\"process_log.log\",\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Define the column names for Excel data\n",
    "columns = ['SNO', 'PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "\n",
    "# Function to process a single file\n",
    "def process_file(file, data_path):\n",
    "    \"\"\"\n",
    "    Processes an Excel file to extract relevant data.\n",
    "\n",
    "    Args:\n",
    "        file (str): The filename of the Excel file to process.\n",
    "        data_path (str): The directory path where the file is located.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary information about the processed file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "\n",
    "        # Check if the file is an Excel file\n",
    "        if file.endswith(\".xls\") or file.endswith(\".xlsx\"):\n",
    "            # Read the Excel file\n",
    "            data = pd.read_excel(\n",
    "                file_path,\n",
    "                sheet_name='ITRS2_URT_RECEIPTS',  # Specify the sheet name\n",
    "                usecols=\"A:H\",                   # Select columns A to H\n",
    "                skiprows=7,                      # Skip the first 7 rows\n",
    "                names=columns                    # Apply column names\n",
    "            )\n",
    "\n",
    "            # Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\n",
    "            filtered_data = data.dropna(subset=['PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "            # Return a summary for the file\n",
    "            return {\n",
    "                \"Filename\": file,\n",
    "                \"FILES_RECEIPTS\": filtered_data.shape[0],\n",
    "                \"INSTITUTIONCODE\": file[:4],\n",
    "                \"REPORTINGDATE\": datetime.strptime(file[8:14], '%d%m%y').strftime('%Y-%m-%d')  # Format as YYYY-MM-DD\n",
    "            }\n",
    "        else:\n",
    "            # Return an error message if the file is not an Excel file\n",
    "            return {\n",
    "                \"Filename\": file,\n",
    "                \"FILES_RECEIPTS\": \"Error: Not an Excel file\",\n",
    "                \"INSTITUTIONCODE\": None,\n",
    "                \"REPORTINGDATE\": None\n",
    "            }\n",
    "    except Exception as e:\n",
    "        # Log the error and return error details\n",
    "        logging.error(f\"Error processing {file}: {e}\")\n",
    "        return {\n",
    "            \"Filename\": file,\n",
    "            \"FILES_RECEIPTS\": f\"Error: {e}\",\n",
    "            \"INSTITUTIONCODE\": None,\n",
    "            \"REPORTINGDATE\": None\n",
    "        }\n",
    "\n",
    "# Main function to process all files\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process all Excel files in the specified directory.\n",
    "    \"\"\"\n",
    "    # Define the directory where all files are located\n",
    "    data_path = r\"C:\\edi_data\"\n",
    "\n",
    "    # List all files in the directory (filtering only Excel files)\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith(\".xls\") or f.endswith(\".xlsx\")]\n",
    "\n",
    "    # Initialize a list to store the output summary\n",
    "    output_summary = []\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing (optimized for I/O-bound tasks)\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Use a lambda to pass both file and data_path to the processing function\n",
    "        results = executor.map(lambda file: process_file(file, data_path), files)\n",
    "\n",
    "        # Collect results from the executor\n",
    "        for result in results:\n",
    "            output_summary.append(result)\n",
    "\n",
    "    # Convert the output summary to a pandas DataFrame for tabular representation\n",
    "    summary_df = pd.DataFrame(output_summary)\n",
    "\n",
    "    # Display the summary DataFrame in the console\n",
    "    print(summary_df)\n",
    "\n",
    "    # Save the summary to a CSV file\n",
    "    summary_csv_path = os.path.join(data_path, \"summary_receipts2.csv\")\n",
    "    summary_df.to_csv(summary_csv_path, index=False)\n",
    "    print(f\"Summary saved to {summary_csv_path}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# #alternative: read files from one path for all data\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Define the path where all files are located\n",
    "# data_path = r\"C:\\edi_data\"\n",
    "\n",
    "# # Define the column names\n",
    "# columns = ['SNO', 'PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "\n",
    "# # Create a list to hold the output data\n",
    "# output_summary = []\n",
    "\n",
    "# # Iterate through all files in the directory\n",
    "# for file in os.listdir(data_path):\n",
    "#     file_path = os.path.join(data_path, file)\n",
    "\n",
    "#     # Check if the file is an Excel file\n",
    "#     if file.endswith(\".xls\") or file.endswith(\".xlsx\"):\n",
    "#         try:\n",
    "#             # Read the Excel file\n",
    "#             data = pd.read_excel(\n",
    "#                 file_path,\n",
    "#                 sheet_name='ITRS2_URT_RECEIPTS',  # Specify the sheet name\n",
    "#                 usecols=\"A:H\",                   # Select columns A to H\n",
    "#                 skiprows=7,                      # Skip the first 7 rows\n",
    "#                 names=columns                    # Apply defined column names\n",
    "#             )\n",
    "\n",
    "#             # Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\n",
    "#             filtered_data = data.dropna(subset=['PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "#             # Append the summary details to the output list\n",
    "#             output_summary.append({\n",
    "#                 \"Filename\": file,\n",
    "#                 \"FILES_RECEIPTS\": filtered_data.shape[0],\n",
    "#                 \"INSTITUTIONCODE\": file[:4],\n",
    "#                 \"REPORTINGDATE\": datetime.strptime(file[8:14], '%d%m%y').strftime('%Y-%m-%d')  # Convert to \"YYYY-MM-DD\" format\n",
    "#             })\n",
    "#         except Exception as e:\n",
    "#             # Append an error message for files that could not be processed\n",
    "#             output_summary.append({\n",
    "#                 \"Filename\": file,\n",
    "#                 \"FILES_RECEIPTS\": f\"Error: {str(e)}\",\n",
    "#                 \"INSTITUTIONCODE\": None,\n",
    "#                 \"REPORTINGDATE\": None\n",
    "#             })\n",
    "\n",
    "# # Convert the summary list to a DataFrame for tabular display\n",
    "# summary_df = pd.DataFrame(output_summary)\n",
    "\n",
    "# # Display the summary DataFrame\n",
    "# print(summary_df)\n",
    "\n",
    "# # Optionally, save the summary to a CSV file\n",
    "# summary_df.to_csv(r\"C:\\edi_data\\summary_receipts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7292fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in EDI query: Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error in BSIS query: Error: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error in BSIS Final query: Error: A process in the process pool was terminated abruptly while the future was running or pending.\n"
     ]
    }
   ],
   "source": [
    "from utils.database import DatabaseConnection\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Define the SQL queries\n",
    "queries = {\n",
    "    \"edi\": {\n",
    "        \"query\": \"\"\"SELECT \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE, \n",
    "                        COUNT(*) AS RECEIPTS\n",
    "                    FROM \n",
    "                        ITRS_URT_RECEIPTS@BSIS_TO_EDI\n",
    "                    GROUP BY \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE\n",
    "                    ORDER BY \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE\"\"\",\n",
    "        \"columns\": [\"INSTITUTIONCODE\", \"REPORTINGDATE\", \"EDI_PAYMENTS\"]\n",
    "    },\n",
    "    \"bsis\": {\n",
    "        \"query\": \"\"\"SELECT \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE, \n",
    "                        COUNT(*) AS RECEIPTS\n",
    "                    FROM \n",
    "                        ITRS_URT_RECEIPTS\n",
    "                    GROUP BY \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE\n",
    "                    ORDER BY \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE\"\"\",\n",
    "        \"columns\": [\"INSTITUTIONCODE\", \"REPORTINGDATE\", \"BSIS_PAYMENTS\"]\n",
    "    },\n",
    "    \"bsis_final\": {\n",
    "        \"query\": \"\"\"SELECT \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE, \n",
    "                        COUNT(*) AS RECEIPTS\n",
    "                    FROM \n",
    "                        ITRS_URT_RECEIPTS_FINAL\n",
    "                    GROUP BY \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE\n",
    "                    ORDER BY \n",
    "                        INSTITUTIONCODE, \n",
    "                        REPORTINGDATE\"\"\",\n",
    "        \"columns\": [\"INSTITUTIONCODE\", \"REPORTINGDATE\", \"BSIS_FINAL_PAYMENTS\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to execute a single query\n",
    "def execute_query(name, query_details):\n",
    "    try:\n",
    "        with DatabaseConnection(\"BSIS\") as conn:\n",
    "            data = conn.execute_query(query_details[\"query\"])\n",
    "            return name, pd.DataFrame(data, columns=query_details[\"columns\"])\n",
    "    except Exception as e:\n",
    "        return name, f\"Error: {str(e)}\"\n",
    "\n",
    "# Main function for concurrent execution\n",
    "def main():\n",
    "    # Store the results\n",
    "    results = {}\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with ProcessPoolExecutor(max_workers=5) as executor:  # Use between 2 to 5 processors\n",
    "        # Map the query execution function to the queries\n",
    "        future_to_query = {\n",
    "            executor.submit(execute_query, name, query_details): name\n",
    "            for name, query_details in queries.items()\n",
    "        }\n",
    "\n",
    "        # Collect the results as they complete\n",
    "        for future in future_to_query:\n",
    "            query_name = future_to_query[future]\n",
    "            try:\n",
    "                name, df_or_error = future.result()\n",
    "                results[name] = df_or_error\n",
    "            except Exception as exc:\n",
    "                results[query_name] = f\"Error: {str(exc)}\"\n",
    "\n",
    "    # Extract DataFrames\n",
    "    edi_df = results.get(\"edi\", pd.DataFrame())\n",
    "    bsis_df = results.get(\"bsis\", pd.DataFrame())\n",
    "    bsis_final_df = results.get(\"bsis_final\", pd.DataFrame())\n",
    "\n",
    "    # Display DataFrames or errors\n",
    "    if isinstance(edi_df, pd.DataFrame):\n",
    "        print(\"EDI DataFrame:\")\n",
    "        print(edi_df.head())\n",
    "    else:\n",
    "        print(f\"Error in EDI query: {edi_df}\")\n",
    "\n",
    "    if isinstance(bsis_df, pd.DataFrame):\n",
    "        print(\"BSIS DataFrame:\")\n",
    "        print(bsis_df.head())\n",
    "    else:\n",
    "        print(f\"Error in BSIS query: {bsis_df}\")\n",
    "\n",
    "    if isinstance(bsis_final_df, pd.DataFrame):\n",
    "        print(\"BSIS Final DataFrame:\")\n",
    "        print(bsis_final_df.head())\n",
    "    else:\n",
    "        print(f\"Error in BSIS Final query: {bsis_final_df}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# #from database\n",
    "# from utils.database import DatabaseConnection\n",
    "# sql_edi = \"\"\"SELECT \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE, \n",
    "#     COUNT(*) AS RECEIPTS\n",
    "# FROM \n",
    "#     ITRS_URT_RECEIPTS@BSIS_TO_EDI\n",
    "# GROUP BY \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE\n",
    "# ORDER BY \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE\"\"\"\n",
    "# sql_bsis = \"\"\"SELECT \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE, \n",
    "#     COUNT(*) AS RECEIPTS\n",
    "# FROM \n",
    "#     ITRS_URT_RECEIPTS\n",
    "\n",
    "# GROUP BY \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE\n",
    "# ORDER BY \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE\"\"\"\n",
    "# sql_bsis_final = \"\"\"SELECT \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE, \n",
    "#     COUNT(*) AS RECEIPTS\n",
    "# FROM \n",
    "#     ITRS_URT_RECEIPTS_FINAL\n",
    "# GROUP BY \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE\n",
    "# ORDER BY \n",
    "#     INSTITUTIONCODE, \n",
    "#     REPORTINGDATE\"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# removed: WHERE\n",
    "#     reportingdate between '31-JAN-18' and '31-DEC-24'\n",
    "# \"\"\"\n",
    "# edi_df = pd.DataFrame()\n",
    "# bsis_df = pd.DataFrame()\n",
    "# bsis_final_df = pd.DataFrame()\n",
    "# with DatabaseConnection(\"BSIS\") as conn:\n",
    "#     try:\n",
    "#         edi_data = conn.execute_query(sql_edi)\n",
    "#         bsis_data =conn.execute_query(sql_bsis)\n",
    "#         bsis_final_data =conn.execute_query(sql_bsis_final)\n",
    "        \n",
    "#         columns1 = [\"INSTITUTIONCODE\",\"REPORTINGDATE\",\"EDI_RECEIPTS\"]    \n",
    "#         columns2 = [\"INSTITUTIONCODE\",\"REPORTINGDATE\",\"BSIS_RECEIPTS\"] \n",
    "#         columns3 = [\"INSTITUTIONCODE\",\"REPORTINGDATE\",\"BSIS_FINAL_RECEIPTS\"]\n",
    "#         edi_df = pd.DataFrame(edi_data, columns=columns1)       \n",
    "#         bsis_df = pd.DataFrame(bsis_data, columns=columns2)\n",
    "#         bsis_final_df = pd.DataFrame(bsis_final_data, columns=columns3)\n",
    "\n",
    "#     except Error as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6193fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from database\n",
    "from utils.database import DatabaseConnection\n",
    "sql_edi = \"\"\"SELECT \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE, \n",
    "    COUNT(*) AS RECEIPTS\n",
    "FROM \n",
    "    ITRS_URT_RECEIPTS@BSIS_TO_EDI\n",
    "GROUP BY \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE\n",
    "ORDER BY \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE\"\"\"\n",
    "sql_bsis = \"\"\"SELECT \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE, \n",
    "    COUNT(*) AS RECEIPTS\n",
    "FROM \n",
    "    ITRS_URT_RECEIPTS\n",
    "\n",
    "GROUP BY \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE\n",
    "ORDER BY \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE\"\"\"\n",
    "sql_bsis_final = \"\"\"SELECT \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE, \n",
    "    COUNT(*) AS RECEIPTS\n",
    "FROM \n",
    "    ITRS_URT_RECEIPTS_FINAL\n",
    "GROUP BY \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE\n",
    "ORDER BY \n",
    "    INSTITUTIONCODE, \n",
    "    REPORTINGDATE\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "removed: WHERE\n",
    "    reportingdate between '31-JAN-18' and '31-DEC-24'\n",
    "\"\"\"\n",
    "edi_df = pd.DataFrame()\n",
    "bsis_df = pd.DataFrame()\n",
    "bsis_final_df = pd.DataFrame()\n",
    "with DatabaseConnection(\"BSIS\") as conn:\n",
    "    try:\n",
    "        edi_data = conn.execute_query(sql_edi)\n",
    "        bsis_data =conn.execute_query(sql_bsis)\n",
    "        bsis_final_data =conn.execute_query(sql_bsis_final)\n",
    "        \n",
    "        columns1 = [\"INSTITUTIONCODE\",\"REPORTINGDATE\",\"EDI_PAYMENTS\"]    \n",
    "        columns2 = [\"INSTITUTIONCODE\",\"REPORTINGDATE\",\"BSIS_PAYMENTS\"] \n",
    "        columns3 = [\"INSTITUTIONCODE\",\"REPORTINGDATE\",\"BSIS_FINAL_PAYMENTS\"]\n",
    "        edi_df = pd.DataFrame(edi_data, columns=columns1)       \n",
    "        bsis_df = pd.DataFrame(bsis_data, columns=columns2)\n",
    "        bsis_final_df = pd.DataFrame(bsis_final_data, columns=columns3)\n",
    "\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7e614a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\edi_data\\\\summary_RECEIPTS3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m  \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43medi_data\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msummary_RECEIPTS3.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m summary_df\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\edi_data\\\\summary_RECEIPTS3.csv'"
     ]
    }
   ],
   "source": [
    "summary_df =  pd.read_csv(r\"C:\\edi_data\\summary_receipts2.csv\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ba2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# # Ensure REPORTINGDATE in `summary_df` is in datetime64 format\n",
    "# summary_df['REPORTINGDATE'] = pd.to_datetime(summary_df['REPORTINGDATE'], format='%Y-%m-%d')\n",
    "\n",
    "# # Function to perform a merge operation\n",
    "# def perform_merge(left_df, right_df, on_columns, how='left'):\n",
    "#     return left_df.merge(right_df, on=on_columns, how=how)\n",
    "\n",
    "# # Main function for merging\n",
    "# def main():\n",
    "#     # List of merging steps with the corresponding DataFrames\n",
    "#     merge_tasks = [\n",
    "#         (summary_df, edi_df, ['INSTITUTIONCODE', 'REPORTINGDATE']),\n",
    "#         (None, bsis_df, ['INSTITUTIONCODE', 'REPORTINGDATE']),  # Placeholder for the intermediate merged result\n",
    "#         (None, bsis_final_df, ['INSTITUTIONCODE', 'REPORTINGDATE'])\n",
    "#     ]\n",
    "\n",
    "#     # Use ProcessPoolExecutor for parallel merging\n",
    "#     with ProcessPoolExecutor(max_workers=5) as executor:\n",
    "#         merged_results = []\n",
    "        \n",
    "#         # Submit the first task (summary_df with edi_df)\n",
    "#         merged_results.append(executor.submit(perform_merge, merge_tasks[0][0], merge_tasks[0][1], merge_tasks[0][2]))\n",
    "        \n",
    "#         # Process subsequent merges sequentially but in parallel using the intermediate results\n",
    "#         for i in range(1, len(merge_tasks)):\n",
    "#             previous_result = merged_results[-1].result()  # Get the intermediate merged result\n",
    "#             merged_results.append(\n",
    "#                 executor.submit(perform_merge, previous_result, merge_tasks[i][1], merge_tasks[i][2])\n",
    "#             )\n",
    "\n",
    "#     # Get the final merged DataFrame\n",
    "#     merged_df = merged_results[-1].result()\n",
    "\n",
    "#     # Define the desired column order\n",
    "#     column_order = [\n",
    "#         'Month', 'Filename', 'INSTITUTIONCODE', \n",
    "#         'REPORTINGDATE', 'FILES_RECEIPTS', \n",
    "#         'EDI_RECEIPTS', 'BSIS_RECEIPTS', \n",
    "#         'BSIS_FINAL_RECEIPTS'\n",
    "#     ]\n",
    "\n",
    "#     # Reorder the columns\n",
    "#     merged_df = merged_df[column_order]\n",
    "\n",
    "#     # Save the final DataFrame to disk\n",
    "#     merged_df.to_csv('urt_receipts_comparison.csv', index=False)\n",
    "\n",
    "#     # Display information about the merged DataFrame\n",
    "#     print(merged_df.info())\n",
    "\n",
    "#     # Display the first few rows of the merged DataFrame\n",
    "#     print(merged_df.head())\n",
    "\n",
    "# # Run the main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "summary_df =  pd.read_csv(r\"C:\\edi_data\\summary_receipts2.csv\")\n",
    "\n",
    "# Ensure REPORTINGDATE in summary_df is in datetime64 format\n",
    "summary_df['REPORTINGDATE'] = pd.to_datetime(summary_df['REPORTINGDATE'], format='%Y-%m-%d')\n",
    "\n",
    "# Merge the DataFrames sequentially\n",
    "merged_df = (\n",
    "    summary_df\n",
    "    .merge(edi_df, on=['INSTITUTIONCODE', 'REPORTINGDATE'], how='left')   # Join with edi_df\n",
    "    .merge(bsis_df, on=['INSTITUTIONCODE', 'REPORTINGDATE'], how='left')  # Join with bsis_df\n",
    "    .merge(bsis_final_df, on=['INSTITUTIONCODE', 'REPORTINGDATE'], how='left')  # Join with bsis_final_df\n",
    ")\n",
    "\n",
    "# Define the desired column order\n",
    "# column_order = [\n",
    "#     'Month', 'Filename', 'INSTITUTIONCODE', \n",
    "#     'REPORTINGDATE', 'FILES_RECEIPTS', \n",
    "#     'EDI_RECEIPTS', 'BSIS_RECEIPTS', \n",
    "#     'BSIS_FINAL_RECEIPTS'\n",
    "# ]\n",
    "\n",
    "# # Reorder the columns\n",
    "# merged_df = merged_df[column_order]\n",
    "# Save in disk\n",
    "merged_df.to_csv(r\"C:\\edi_data\\urt_receipts_comparison.csv\")\n",
    "# Display information about the merged DataFrame\n",
    "print(merged_df.info())\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b0b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92f4151-48fd-4d6f-b7e6-7c4dc3e257c3",
   "metadata": {},
   "source": [
    "#### UPDATING RECEIPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a9b3984-04e0-4c47-893f-fa8c635f7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 file  status  \\\n",
      "0  A1991078300924.xls  Failed   \n",
      "\n",
      "                                               error  \n",
      "0  Oracle Database FLOAT types use 'binary precis...  \n",
      "Summary saved to C:\\edi_data\\test\\summary_receipts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\255759804774\\AppData\\Local\\Temp\\ipykernel_1148\\2637674680.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['INSTITUTIONCODE'] = file[:4]\n",
      "C:\\Users\\255759804774\\AppData\\Local\\Temp\\ipykernel_1148\\2637674680.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['REPORTINGDATE']  =  datetime.strptime(file[8:14], '%d%m%y').strftime('%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "import oracledb\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "filtered_data = pd.DataFrame()\n",
    "# Configure logging for error tracking\n",
    "logging.basicConfig(\n",
    "    filename=\"process_log.log\",\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Oracle Database connection details\n",
    "db_user = \"BSIS_DEV\"\n",
    "db_password = \"bsis_dev\"\n",
    "db_host = \"172.16.1.167\"\n",
    "db_port = \"1521\"  # Default: 1521\n",
    "db_service_name = \"BOT1DB\"  # Use service name instead of SID\n",
    "table_name = \"ITRS_URS_RECEIPTS\"\n",
    "\n",
    "# Enable Oracle Thick mode if needed (Uncomment if using Oracle Instant Client)\n",
    "# oracledb.init_oracle_client(lib_dir=r\"C:\\oracle\\instantclient_19_8\")\n",
    "\n",
    "# Create Oracle database engine using `oracledb`\n",
    "oracle_dsn = f\"{db_host}:{db_port}/{db_service_name}\"\n",
    "#engine = create_engine(f\"oracle+oracledb://{db_user}:{db_password}@{oracle_dsn}\")\n",
    "\n",
    "# Define the directory containing the Excel files\n",
    "data_path = r\"C:\\edi_data\\test\"\n",
    "\n",
    "# Define the column names for Excel data\n",
    "columns = ['SNO', 'PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "#filtered_data = pd.DataFrame()\n",
    "# Function to process a single file\n",
    "def process_file(file, engine):\n",
    "    \"\"\"\n",
    "    Processes an Excel file to extract relevant data.\n",
    "\n",
    "    Args:\n",
    "        file (str): The filename of the Excel file to process.\n",
    "        data_path (str): The directory path where the file is located.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary information about the processed file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "\n",
    "        # Check if the file is an Excel file\n",
    "        if file.endswith(\".xls\") or file.endswith(\".xlsx\"):\n",
    "            # Read the Excel file\n",
    "            data = pd.read_excel(\n",
    "                file_path,\n",
    "                sheet_name='ITRS2_URT_RECEIPTS',  # Specify the sheet name\n",
    "                usecols=\"A:H\",                   # Select columns A to H\n",
    "                skiprows=7,                      # Skip the first 7 rows\n",
    "                names=columns                    # Apply column names\n",
    "            )\n",
    "\n",
    "            # Filter rows where columns PURPOSE to DESCRIPTION are not empty or null\n",
    "            filtered_data = data.dropna(subset=['PURPOSE', 'CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "            filtered_data['INSTITUTIONCODE'] = file[:4]\n",
    "            filtered_data['REPORTINGDATE']  =  datetime.strptime(file[8:14], '%d%m%y').strftime('%Y-%m-%d') \n",
    "            \n",
    "            # Insert data into Oracle database\n",
    "            with engine.begin() as connection:\n",
    "                filtered_data.to_sql(\n",
    "                    table_name,\n",
    "                    connection,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    method='multi',\n",
    "                    chunksize=1000  # Optimize batch insert\n",
    "                )\n",
    "\n",
    "            logging.info(f\"Processed {file}: {len(filtered_data)} rows inserted successfully.\")\n",
    "            return {\"file\": file, \"status\": \"Success\", \"rows_inserted\": len(filtered_data)}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {file}: {e}\")\n",
    "        return {\"file\": file, \"status\": \"Failed\", \"error\": str(e)}\n",
    "\n",
    "\n",
    "# Main function to process all files\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process all Excel files in the specified directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # List all files in the directory (filtering only Excel files)\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith(\".xls\") or f.endswith(\".xlsx\")]\n",
    "\n",
    "    # Initialize a list to store the output summary\n",
    "    output_summary = []\n",
    "\n",
    "    # Create a single database engine instance for thread safety\n",
    "    engine = create_engine(f\"oracle+oracledb://{db_user}:{db_password}@{oracle_dsn}\")\n",
    "\n",
    "    # Process files concurrently\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_file = {executor.submit(process_file, file, engine): file for file in files}\n",
    "\n",
    "        for future in as_completed(future_to_file):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                output_summary.append(result)\n",
    "\n",
    "    \n",
    "    # Convert the output summary to a pandas DataFrame\n",
    "    summary_df = pd.DataFrame(output_summary)\n",
    "\n",
    "    # Display the summary\n",
    "    print(summary_df)\n",
    "\n",
    "    # Save the summary to a CSV file\n",
    "    summary_csv_path = os.path.join(data_path, \"summary_receipts.csv\")\n",
    "    summary_df.to_csv(summary_csv_path, index=False)\n",
    "    print(f\"Summary saved to {summary_csv_path}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09a7c95-a231-46b7-b2e3-a8c154ef69cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97b765e8-56ca-4b2c-b89c-21c407262132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97ee7946-9a58-4192-8db1-0304f89e6dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to C:\\edi_data\\test\\summary_receipts.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"process_log.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Oracle Database connection details\n",
    "# DB_USER = \"BSIS_DEV\"\n",
    "# DB_PASSWORD = \"bsis_dev\"\n",
    "# DB_HOST = \"172.16.1.167\"\n",
    "# DB_PORT = \"1521\"\n",
    "# DB_SERVICE_NAME = \"BOT1DB\"\n",
    "DB_USER = \"EDI\"\n",
    "DB_PASSWORD = \"edi\"\n",
    "DB_HOST = \"172.16.2.122\"  #EDI PROD\n",
    "DB_PORT = \"1521\"\n",
    "DB_SERVICE_NAME = \"EDIPROD\"\n",
    "TABLE_NAME = \"ITRS_URT_RECEIPTS\"\n",
    "\n",
    "# File processing directory\n",
    "DATA_PATH = r\"C:\\edi_data\\test\"\n",
    "\n",
    "# Define expected column names (Mapped to DB)\n",
    "COLUMNS = ['DESCRIPTIONNO', 'PURPOSE', 'PU_CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION']\n",
    "\n",
    "# Create database engine\n",
    "def create_db_engine():\n",
    "    oracle_dsn = f\"{DB_HOST}:{DB_PORT}/{DB_SERVICE_NAME}\"\n",
    "    engine = create_engine(\n",
    "        f\"oracle+oracledb://{DB_USER}:{DB_PASSWORD}@{oracle_dsn}\",\n",
    "        pool_size=5, max_overflow=10\n",
    "    )\n",
    "    return engine\n",
    "\n",
    "# Process each file and insert/update into database\n",
    "def process_file(file, engine):\n",
    "    try:\n",
    "        file_path = os.path.join(DATA_PATH, file)\n",
    "        if not file.endswith((\".xls\", \".xlsx\")):\n",
    "            return {\"file\": file, \"status\": \"Skipped\", \"reason\": \"Invalid file format\"}\n",
    "\n",
    "        # Read and clean data\n",
    "        df = pd.read_excel(\n",
    "            file_path, sheet_name='ITRS2_URT_RECEIPTS', usecols=\"A:H\", skiprows=7, names=COLUMNS\n",
    "        ).dropna(subset=['PURPOSE', 'PU_CODE', 'COUNTRY', 'SECTOR', 'CURRENCY', 'AMOUNT', 'DESCRIPTION'])\n",
    "\n",
    "        # Extract institution code\n",
    "        reporting_date_str = file[:4]\n",
    "        df['REPORTINGDATE'] = datetime.strptime(reporting_date_str, '%d%m%y').date()\n",
    "        #df['INSTITUTIONCODE'] = file[:4]\n",
    "        df['DESCRIPTIONNO'] = df['DESCRIPTIONNO'].fillna(0).astype(int)\n",
    "        print(f\"Extracted reporting date: {df['REPORTINGDATE'].unique()}\")\n",
    "\n",
    "        # Extract and validate reporting date\n",
    "        reporting_date_str = file[8:14]\n",
    "        try:\n",
    "            df['REPORTINGDATE'] = pd.to_datetime(reporting_date_str, format='%d%m%y').dt.date\n",
    "        except ValueError:\n",
    "            return {\"file\": file, \"status\": \"Failed\", \"error\": f\"Invalid date format: {reporting_date_str}\"}\n",
    "        \n",
    "        # Add missing 'STATUS' column (defaulting to 'N' for New)\n",
    "        df['STATUS'] = 'N'\n",
    "\n",
    "        # Insert or Update logic (UPSERT)\n",
    "        insert_update_sql = text(f\"\"\"\n",
    "            MERGE INTO {TABLE_NAME} tgt\n",
    "            USING (VALUES (:INSTITUTIONCODE, :REPORTINGDATE, :DESCRIPTIONNO, :PURPOSE, \n",
    "               :PU_CODE, :COUNTRY, :SECTOR, :CURRENCY, :AMOUNT, :DESCRIPTION, :STATUS)) src\n",
    "            ON (tgt.INSTITUTIONCODE = src.INSTITUTIONCODE \n",
    "                AND tgt.REPORTINGDATE = src.REPORTINGDATE\n",
    "                AND tgt.DESCRIPTIONNO = src.DESCRIPTIONNO)\n",
    "            WHEN MATCHED THEN \n",
    "                UPDATE SET tgt.PURPOSE = src.PURPOSE,\n",
    "                           tgt.PU_CODE = src.PU_CODE,\n",
    "                           tgt.COUNTRY = src.COUNTRY,\n",
    "                           tgt.SECTOR = src.SECTOR,\n",
    "                           tgt.CURRENCY = src.CURRENCY,\n",
    "                           tgt.AMOUNT = src.AMOUNT,\n",
    "                           tgt.DESCRIPTION = src.DESCRIPTION,\n",
    "                           tgt.STATUS = src.STATUS\n",
    "            WHEN NOT MATCHED THEN\n",
    "                INSERT (INSTITUTIONCODE, REPORTINGDATE, DESCRIPTIONNO, PURPOSE, PU_CODE, COUNTRY, SECTOR, CURRENCY, AMOUNT, DESCRIPTION, STATUS)\n",
    "                VALUES (src.INSTITUTIONCODE, src.REPORTINGDATE, src.DESCRIPTIONNO, src.PURPOSE, src.PU_CODE, src.COUNTRY, src.SECTOR, src.CURRENCY, src.AMOUNT, src.DESCRIPTION, src.STATUS)\n",
    "        \"\"\")\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            for _, row in df.iterrows():\n",
    "                conn.execute(insert_update_sql, **row.to_dict())\n",
    "            conn.commit()  # Ensure changes persist\n",
    "\n",
    "        logging.info(f\"Processed {file}: {len(df)} rows inserted/updated successfully.\")\n",
    "        print(f\"Processed {file}: {len(df)} rows inserted/updated successfully.\")\n",
    "        return {\"file\": file, \"status\": \"Success\", \"rows_processed\": len(df)}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {file}: {e}\\n{traceback.format_exc()}\")\n",
    "        return {\"file\": file, \"status\": \"Failed\", \"error\": str(e)}\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    files = [f for f in os.listdir(DATA_PATH) if f.endswith((\".xls\", \".xlsx\"))]\n",
    "    if not files:\n",
    "        print(\"No files found to process.\")\n",
    "        return\n",
    "\n",
    "    #engine = create_db_engine()\n",
    "    engine = create_engine(\n",
    "        f\"oracle+cx_oracle://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/?service_name={DB_SERVICE_NAME}\",\n",
    "        pool_size=5, max_overflow=10\n",
    "    )\n",
    "    output_summary = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {executor.submit(process_file, file, engine): file for file in files}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                output_summary.append(result)\n",
    "\n",
    "    # Save summary report\n",
    "    summary_df = pd.DataFrame(output_summary)\n",
    "    summary_csv_path = os.path.join(DATA_PATH, \"summary_receipts.csv\")\n",
    "    summary_df.to_csv(summary_csv_path, index=False)\n",
    "    print(f\"Summary saved to {summary_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad010f35-202f-4f39-85da-1243aca19246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf99454-ca17-46da-9c70-108633d5b02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953ab3f-b9c5-4c1a-abb6-dee8ee07e3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979bcea1-d1b0-4f59-8cdc-34fdca4ef6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f58d3-e1d7-41a4-8c45-bc8fc5a6174a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e251496-5068-45ee-aca9-53ee873ac536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e79ac8-716a-4d79-bebb-2f3273d9005c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abb53d-19d0-4878-bcb3-62513d1744fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda3d45-78d3-4241-80bb-edf16b46ea6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a132e20-b389-4c93-a1fd-4c5e5124f099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cecd4f-36e4-4598-9769-f4b4a27da236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c14a7-d623-4548-9d3b-d74e14636153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9b663-c2ed-4540-bd5d-1eaa7fbfc61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
